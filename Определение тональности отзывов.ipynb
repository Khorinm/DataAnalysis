{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача: определение тональности отзывов при помощи наивного байесовского классификатора.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_path = \"./txt_sentoken/pos/\"\n",
    "neg_path = \"./txt_sentoken/neg/\"\n",
    "\n",
    "def convert_text(s):\n",
    "    # Removes all characters from string except letters and digits and convert letters to lowercase\n",
    "    return re.sub(\"[^a-zA-Z0-9]\", \" \", s.lower())\n",
    "\n",
    "def read_txts(dir_path=\"./txt_sentoken/pos/\"):\n",
    "    # Reads all files from directory\n",
    "    if dir_path[-1] != \"/\":\n",
    "        dir_path = dir_path + \"/\"\n",
    "    txt_list = []\n",
    "    for file in os.listdir(dir_path):\n",
    "        file = dir_path + file\n",
    "        fin = open(file, 'r')\n",
    "        txt = \" \".join(fin.readlines())\n",
    "        txt = convert_text(txt)\n",
    "        txt_list.append(txt)\n",
    "    return txt_list\n",
    "\n",
    "def read_datasets(pos_path, neg_path):\n",
    "    positive = read_txts(pos_path)\n",
    "    negative = read_txts(neg_path)\n",
    "    return positive, negative\n",
    "\n",
    "\n",
    "def split_data(pos, neg):\n",
    "    positive_train, negative_train = pos[:700], neg[:700]\n",
    "    positive_test, negative_test = pos[700:],neg[700:]\n",
    "    return positive_train, negative_train, positive_test, negative_test\n",
    "\n",
    "def make_labels(data, is_positive = True):\n",
    "        if is_positive:\n",
    "            return np.array([1 for x in data])\n",
    "        else:\n",
    "            return np.array([0 for x in data])\n",
    "\n",
    "def score_accuracy(test_Y, predicted):\n",
    "    return print (\"Accuracy is\", np.mean(test_Y == predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### №7 A method to determine review type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def determine_type(review, classifier, vectorizer):\n",
    "    txt_list = []\n",
    "    review = convert_text(review)\n",
    "    txt_list.append(review)\n",
    "    X = vectorizer.transform(txt_list).toarray()\n",
    "    prediction = classifier.predict(X)\n",
    "    if prediction[0] == 1:\n",
    "        return print('The review is positive')\n",
    "    else:\n",
    "        return print ('The review is negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "positive, negative = read_datasets(pos_path, neg_path)\n",
    "\n",
    "# Splitting data \n",
    "positive_train, negative_train, positive_test, negative_test = split_data(positive, negative)\n",
    "\n",
    "# Preparing labels\n",
    "pos_train_labels, neg_train_labels = make_labels(positive_train), make_labels(negative_train, False)\n",
    "pos_test_lables, neg_test_labels = make_labels(positive_test), make_labels(negative_test, False)\n",
    "\n",
    "# Training data\n",
    "train_X = positive_train + negative_train\n",
    "train_Y = np.append(pos_train_labels, neg_train_labels)\n",
    "\n",
    "# Testing data\n",
    "test_X = positive_test + negative_test\n",
    "test_Y = np.append(pos_test_lables, neg_test_labels)\n",
    "\n",
    "# Training vectorizer\n",
    "vectorizer = CountVectorizer().fit(train_X)\n",
    "\n",
    "# Applying vectorization\n",
    "train_X =vectorizer.transform(train_X).toarray()\n",
    "test_X = vectorizer.transform(test_X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PoissonNB:\n",
    "    def __init__(self, class_prior=None):\n",
    "        \"\"\"\n",
    "        class_prior : np.array, size (n_classes,)\n",
    "        Prior probabilities of the classes. If specified the priors are not\n",
    "        adjusted according to the data.\n",
    "        \"\"\"\n",
    "        self.probabilities = class_prior\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y, epsilon=1e-9):\n",
    "        \"\"\"\n",
    "        Fit Poisson Naive Bayes according to X, y\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.array, shape (n_samples, n_features)\n",
    "            Training vectors, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : np.array, shape (n_samples,)\n",
    "            Target values.\n",
    "        \"\"\"\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        n_samples = X.shape[0]\n",
    "        n_features = X.shape[1]\n",
    "        \n",
    "        classes = set(y)\n",
    "        self.classes = classes\n",
    "        splitted_samples = {}\n",
    "        \n",
    "        for y_class in classes:\n",
    "            splitted_samples[y_class] = np.array([])\n",
    "            \n",
    "        for i in range(0, n_samples):\n",
    "            splitted_samples[y[i]] = np.append(splitted_samples[y[i]], X[i])\n",
    "            \n",
    "        self.num_classes = len(classes)\n",
    "        self.lambdas = np.zeros((self.num_classes, n_features))\n",
    "        \n",
    "        for y_class in classes:\n",
    "            # Taking all samples of a single class\n",
    "            class_samples = splitted_samples[y_class]\n",
    "            num_class_samples = len(class_samples)\n",
    "\n",
    "            # Going through each feature of class samples\n",
    "            self.lambdas[y_class] = np.sum(class_samples, axis=0)\n",
    "\n",
    "        print('Classifier is trained')\n",
    "\n",
    "    def calculate_arg_max(self, x):\n",
    "        maxargs = []\n",
    "        total_sum = 0.0\n",
    "        for i in range(0, len(self.classes)):\n",
    "            for j in range(0, x.shape[0]):\n",
    "                if self.probabilities is None:\n",
    "                    probability = np.random.uniform()\n",
    "                else:\n",
    "                    probability = self.probabilities[i]\n",
    "\n",
    "                log = x[j] * np.log(self.lambdas[i][j] + self.epsilon)\n",
    "                total_sum += log - self.lambdas[i][j] + np.log(probability + self.epsilon)\n",
    "\n",
    "            maxargs.append(total_sum)\n",
    "\n",
    "        return maxargs.index(max(maxargs))    \n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Perform classification on an array of test vectors X.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.array, shape = [n_samples, n_features]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        C : np.array, shape = [n_samples]\n",
    "            Predicted target values for X\n",
    "        \"\"\"\n",
    "        return np.array([self.calculate_arg_max(x) for x in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.621666666667\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(train_X, train_Y)\n",
    "y_predicted_GNB = gnb.predict(test_X)\n",
    "score_accuracy(test_Y, y_predicted_GNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.816666666667\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(train_X, train_Y)\n",
    "y_predicted_MNB = mnb.predict(test_X)\n",
    "score_accuracy(test_Y, y_predicted_MNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poisson classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier is trained\n",
      "Accuracy is 0.5\n"
     ]
    }
   ],
   "source": [
    "pnb = PoissonNB()\n",
    "pnb.fit(train_X, train_Y)\n",
    "y_predicted_PNB = pnb.predict(test_X)\n",
    "score_accuracy(test_Y, y_predicted_PNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing method from №7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review is positive\n"
     ]
    }
   ],
   "source": [
    "determine_type(\"\"\"films adapted from comic books have had plenty of success , whether they're about superheroes ( batman , superman , spawn ) , or geared toward kids ( casper ) or the arthouse crowd ( ghost world ) , but there's never really been a comic book like from hell before . \n",
    "for starters , it was created by alan moore ( and eddie campbell ) , who brought the medium to a whole new level in the mid '80s with a 12-part series called the watchmen . \n",
    "to say moore and campbell thoroughly researched the subject of jack the ripper would be like saying michael jackson is starting to look a little odd . \n",
    "the book ( or \" graphic novel , \" if you will ) is over 500 pages long and includes nearly 30 more that consist of nothing but footnotes . \n",
    "in other words , don't dismiss this film because of its source . \n",
    "if you can get past the whole comic book thing , you might find another stumbling block in from hell's directors , albert and allen hughes . \n",
    "getting the hughes brothers to direct this seems almost as ludicrous as casting carrot top in , well , anything , but riddle me this : who better to direct a film that's set in the ghetto and features really violent street crime than the mad geniuses behind menace ii society ? \n",
    "the ghetto in question is , of course , whitechapel in 1888 london's east end . \n",
    "it's a filthy , sooty place where the whores ( called \" unfortunates \" ) are starting to get a little nervous about this mysterious psychopath who has been carving through their profession with surgical precision . \n",
    "when the first stiff turns up , copper peter godley ( robbie coltrane , the world is not enough ) calls in inspector frederick abberline ( johnny depp , blow ) to crack the case . \n",
    "abberline , a widower , has prophetic dreams he unsuccessfully tries to quell with copious amounts of absinthe and opium . \n",
    "upon arriving in whitechapel , he befriends an unfortunate named mary kelly ( heather graham , say it isn't so ) and proceeds to investigate the horribly gruesome crimes that even the police surgeon can't stomach . \n",
    "i don't think anyone needs to be briefed on jack the ripper , so i won't go into the particulars here , other than to say moore and campbell have a unique and interesting theory about both the identity of the killer and the reasons he chooses to slay . \n",
    "in the comic , they don't bother cloaking the identity of the ripper , but screenwriters terry hayes ( vertical limit ) and rafael yglesias ( les mis ? rables ) do a good job of keeping him hidden from viewers until the very end . \n",
    "it's funny to watch the locals blindly point the finger of blame at jews and indians because , after all , an englishman could never be capable of committing such ghastly acts . \n",
    "and from hell's ending had me whistling the stonecutters song from the simpsons for days ( \" who holds back the electric car/who made steve guttenberg a star ? \" ) . \n",
    "don't worry - it'll all make sense when you see it . \n",
    "now onto from hell's appearance : it's certainly dark and bleak enough , and it's surprising to see how much more it looks like a tim burton film than planet of the apes did ( at times , it seems like sleepy hollow 2 ) . \n",
    "the print i saw wasn't completely finished ( both color and music had not been finalized , so no comments about marilyn manson ) , but cinematographer peter deming ( don't say a word ) ably captures the dreariness of victorian-era london and helped make the flashy killing scenes remind me of the crazy flashbacks in twin peaks , even though the violence in the film pales in comparison to that in the black-and-white comic . \n",
    "oscar winner martin childs' ( shakespeare in love ) production design turns the original prague surroundings into one creepy place . \n",
    "even the acting in from hell is solid , with the dreamy depp turning in a typically strong performance and deftly handling a british accent . \n",
    "ians holm ( joe gould's secret ) and richardson ( 102 dalmatians ) log in great supporting roles , but the big surprise here is graham . \n",
    "i cringed the first time she opened her mouth , imagining her attempt at an irish accent , but it actually wasn't half bad . \n",
    "the film , however , is all good . \n",
    "2 : 00 - r for strong violence/gore , sexuality , language and drug content \n",
    " \n",
    "\"\"\", mnb, vectorizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### №8 Сделайте выводы, почему наивный байесовский классификатор плохо или хорошо работает для данной задачи\n",
    "Вывод: наивный байесовский классификатор является <u>эффективным</u> алгоритмом для классификации текстов, потому что показывает высокую точность классификации, хорошо работает даже с небольшим количеством данных для обучения, относительно прост в реализации, быстр и стабилен, даже не смотря на допущение о независимости признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus 2\n",
    "Applying 3 kind of classificators to <b>polarity dataset v0.9</b> (downloaded from http://www.cs.cornell.edu/People/pabo/movie-review-data/)\n",
    "\n",
    "download link: http://www.cs.cornell.edu/people/pabo/movie-review-data/mix20_rand700_tokens.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_pos_path = \"./tokens/pos/\"\n",
    "new_neg_path = \"./tokens/neg/\"\n",
    "\n",
    "# Reading data\n",
    "n_positive, n_negative = read_datasets(new_pos_path, new_neg_path)\n",
    "\n",
    "# Splitting data\n",
    "n_positive_train, n_negative_train = n_positive[:500], n_negative[:500]\n",
    "n_positive_test, n_negative_test = n_positive[500:],n_negative[500:]\n",
    "\n",
    "# Making labels\n",
    "n_pos_train_labels, n_neg_train_labels = make_labels(n_positive_train), make_labels(n_negative_train, False)\n",
    "n_pos_test_lables, n_neg_test_labels = make_labels(n_positive_test), make_labels(n_negative_test, False)\n",
    "\n",
    "# Training data\n",
    "new_train_X = n_positive_train + n_negative_train\n",
    "new_train_Y = np.append(n_pos_train_labels, n_neg_train_labels)\n",
    "\n",
    "# Testing data\n",
    "new_test_X = n_positive_test + n_negative_test\n",
    "new_test_Y = np.append(n_pos_test_lables, n_neg_test_labels)\n",
    "\n",
    "# Training vectorizer\n",
    "new_vectorizer = CountVectorizer().fit(new_train_X)\n",
    "\n",
    "# Applying vectorization\n",
    "new_train_X = vectorizer.transform(new_train_X).toarray()\n",
    "new_test_X = vectorizer.transform(new_test_X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.635\n"
     ]
    }
   ],
   "source": [
    "gnb.fit(new_train_X, new_train_Y)\n",
    "new_y_predicted_GNB = gnb.predict(new_test_X)\n",
    "score_accuracy(new_test_Y, new_y_predicted_GNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.835\n"
     ]
    }
   ],
   "source": [
    "mnb.fit(new_train_X, new_train_Y)\n",
    "new_y_predicted_MNB = mnb.predict(new_test_X)\n",
    "score_accuracy(new_test_Y, new_y_predicted_MNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poisson classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier is trained\n",
      "Accuracy is 0.5\n"
     ]
    }
   ],
   "source": [
    "pnb.fit(new_train_X, new_train_Y)\n",
    "new_y_predicted_PNB = pnb.predict(new_test_X)\n",
    "score_accuracy(new_test_Y, new_y_predicted_PNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
