{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравнение стилей (PyMorphy & NLTK)\n",
    "### Выполнил: Хорин М. А."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках выполнения домашнего задания необходимо для коллекции текстов разных стилей проверить гипотезу о том, что частоты частей речи в них имеют разные характеры распределений.<br><br>\n",
    "<b>1.</b> По составленным коллекциям публицистического и художественного стилей посчитаем количество токенов и типов в каждой из них."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Для публицистического стиля\n",
    "Чтобы считать количество токенов и типов в коллекции изначально необходимо считать файл с текстовыми данными, а затем произвести очистку текста от знаков пунктуации и иных ненужных символов.<br><br>\n",
    "Для начала считаем файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "publicistic_file = 'publicistic.txt' # запоминаем файл с коллекцией текстов публицистического стиля\n",
    "publicistic_collection = open(publicistic_file, encoding='utf-8-sig').read() # считываем файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Президент России Владимир Путин прокомментировал ситуацию в Донбассе, заявив, что ее обострение спровоцировано украинской стороной. Такое заявление российский президент сделал на пресс-конференции в Будапеште после встречи с премьером Венгрии Виктором Орбаном. Путин подчеркнул, что обострение ситуации в Донбассе спровоцировала украинская сторона. Отвечая на вопрос журналистов, что стало причиной обострения ситуации, президент сказал, что их несколько. «Первая причина заключается в том, что украинскому руководству сегодня нужны деньги, деньги лучше всего вышибать из Евросоюза, отдельных стран Европы, из Соединенных Штатов и из международных финансовых институтов, выставляя себя в качестве жертвы агрессии», — сказал президент (цитата по РИА Новости). Путин также считает, что обострением ситуации в Донбассе Киев «затыкает» оппозицию, которая активизировалась на фоне «явных неудач в сфере экономической и социальной политик». Кроме того, по мнению Путина, сегодняшняя украинская власть «не г'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publicistic_collection[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно заметить выше, исходные текстовые данные малопригодны для обработки, поскольку содержат знаки пунктуации, символы кодировки, числовые знаки и иной ненужный мусор, от которого необходимо избавиться.<br><br>\n",
    "Для предобработки коллекции текстов была создана функция preprocess_text, которая очищает исходные текстовые данные, используя библиотеку string, и делает их пригодными для дальнейшей обработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def preprocess_text(collection):\n",
    "    exclude = set(punctuation + u'0123456789№[]—«»–\\n'+ '\"\"') # множество элементов для исключения из коллекции\n",
    "    collection = collection.replace('-',' ') # разделение элементов коллекции типа \"из-за\" на отдельные части, разделенные пробелом\n",
    "    collection = \"\".join(c for c in collection if c not in exclude) # посимвольный анализ коллекции с исключением лишних элементов\n",
    "    collection.replace('\\u200b', '') # очистка коллекции от знаков старой кодировки\n",
    "    return collection.lower() # возвращение очищенной коллекции в нижнем регистре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'президент россии владимир путин прокомментировал ситуацию в донбассе заявив что ее обострение спровоцировано украинской стороной такое заявление российский президент сделал на пресс конференции в будапеште после встречи с премьером венгрии виктором орбаном путин подчеркнул что обострение ситуации в донбассе спровоцировала украинская сторона отвечая на вопрос журналистов что стало причиной обострения ситуации президент сказал что их несколько первая причина заключается в том что украинскому руководству сегодня нужны деньги деньги лучше всего вышибать из евросоюза отдельных стран европы из соединенных штатов и из международных финансовых институтов выставляя себя в качестве жертвы агрессии  сказал президент цитата по риа новости путин также считает что обострением ситуации в донбассе киев затыкает оппозицию которая активизировалась на фоне явных неудач в сфере экономической и социальной политик кроме того по мнению путина сегодняшняя украинская власть не готова вообще к реализации мински'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publicistic_collection = preprocess_text(publicistic_collection)\n",
    "publicistic_collection[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно заметить выше, теперь коллекция текстов пригодна для полноценной обработки.<br><br>\n",
    "Посчитаем количество токенов и типов в коллекции, используя библиотеку nltk. Разобьем коллекцию на токены, используя токенизатор WhitespaceTokenizer, а типы в коллекции определим через частотный словарь nltk.FreqDist()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество токенов в коллекции текстов публицистичекого стиля: 5044\n",
      "Количество типов в коллекции текстов публицистичекого стиля: 2594\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "tokenizer = WhitespaceTokenizer() # создаем токенизатор\n",
    "\n",
    "publicistic_tokens = tokenizer.tokenize(publicistic_collection) # разбиваем коллекцию на токены\n",
    "publicistic_types = nltk.FreqDist(publicistic_tokens) # определяем типы\n",
    "\n",
    "print('Количество токенов в коллекции текстов публицистичекого стиля:', len(publicistic_tokens)) # подсчитываем количество токенов\n",
    "print('Количество типов в коллекции текстов публицистичекого стиля:', len(publicistic_types)) # подсчитываем количество типов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['президент',\n",
       " 'россии',\n",
       " 'владимир',\n",
       " 'путин',\n",
       " 'прокомментировал',\n",
       " 'ситуацию',\n",
       " 'в',\n",
       " 'донбассе',\n",
       " 'заявив',\n",
       " 'что']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publicistic_tokens[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно заметить выше, коллекция разбита на токены верно.<br>\n",
    "Теперь повторим вышеописанные операции для коллекции текстов художественного стиля. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Для художественного стиля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fiction_lit_file = 'fiction_lit.txt'\n",
    "fiction_collection = open(fiction_lit_file, encoding='utf-8-sig').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Мне потребовалось много лет и странствий по всему миру, чтобы узнать все то, что я знаю о любви, о судьбе и о выборе, который мы делаем в жизни, но самое главное я понял в тот миг, когда меня, прикованного цепями к стене, избивали. Мой разум кричал, однако и сквозь этот крик я сознавал, что даже в этом распятом беспомощном состоянии я свободен – я могу ненавидеть своих мучителей или простить их. Свобода, казалось бы, весьма относительная, но когда ты ощущаешь только приливы и отливы боли, она открывает перед тобой целую вселенную возможностей. И сделанный тобой выбор между ненавистью и прощением может стать историей твоей жизни. \\nВ моем случае это долгая история, заполненная людьми и событиями. Я был революционером, растерявшим свои идеалы в наркотическом тумане, философом, потерявшим самого себя в мире преступности, и поэтом, утратившим свой дар в тюрьме особо строгого режима. Сбежав из этой тюрьмы через стену между двумя пулеметными вышками, я стал самым популярным в стране человеком'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fiction_collection[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'мне потребовалось много лет и странствий по всему миру чтобы узнать все то что я знаю о любви о судьбе и о выборе который мы делаем в жизни но самое главное я понял в тот миг когда меня прикованного цепями к стене избивали мой разум кричал однако и сквозь этот крик я сознавал что даже в этом распятом беспомощном состоянии я свободен  я могу ненавидеть своих мучителей или простить их свобода казалось бы весьма относительная но когда ты ощущаешь только приливы и отливы боли она открывает перед тобой целую вселенную возможностей и сделанный тобой выбор между ненавистью и прощением может стать историей твоей жизни в моем случае это долгая история заполненная людьми и событиями я был революционером растерявшим свои идеалы в наркотическом тумане философом потерявшим самого себя в мире преступности и поэтом утратившим свой дар в тюрьме особо строгого режима сбежав из этой тюрьмы через стену между двумя пулеметными вышками я стал самым популярным в стране человеком  ни с кем не искали встречи '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fiction_collection = preprocess_text(fiction_collection)\n",
    "fiction_collection[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество токенов в коллекции текстов художественного стиля: 5115\n",
      "Количество типов: в коллекции текстов художественного стиля: 2637\n"
     ]
    }
   ],
   "source": [
    "fiction_tokens = tokenizer.tokenize(fiction_collection)\n",
    "fiction_types = nltk.FreqDist(fiction_tokens)\n",
    "print('Количество токенов в коллекции текстов художественного стиля:', len(fiction_tokens))\n",
    "print('Количество типов: в коллекции текстов художественного стиля:', len(fiction_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['мне',\n",
       " 'потребовалось',\n",
       " 'много',\n",
       " 'лет',\n",
       " 'и',\n",
       " 'странствий',\n",
       " 'по',\n",
       " 'всему',\n",
       " 'миру',\n",
       " 'чтобы']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fiction_tokens[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.</b> Используя морфологический процессор pymorphy2, определим к какой части речи относятся слова из каждой коллекции текстов. При помощи nltk.FreqDist() составим частотные словари: часть речи - количество слов, к ней относящихся."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для выполнения данного пункта ДЗ необходимо сначала узнать, какие части речи встречаются в обеих коллекциях текстов. Для этого была реализована функция makePOSList, которая, анализируя части речи типов коллекции, возвращает список частей речи, которые встречаются в ней. \n",
    "<br><br>\n",
    "Создание частотного словаря часть речи - количество слов для коллекции текстов реализуется через функцию makePOSFreqDict и осуществляется следующим образом: \n",
    "<ol>\n",
    "<li>Создаётся исходный частотный словарь, содержащий в качестве ключей части речи, встречающиеся в коллекции;</li>\n",
    "<li>Для каждой последовательно анализируемой части речи, встречающейся в списке частей речи коллекции, подсчитывается количество слов, которые к ней относятся. Данное количество добавляется в исходный словарь.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "analyzer = MorphAnalyzer() # морфологический анализатор\n",
    "\n",
    "def makePOSList(types):\n",
    "    POS_list = [] # создание списка частей речи\n",
    "    for t in types: #  идём по всем типам коллекции\n",
    "        gram_POS = analyzer.parse(t)[0].tag.POS # смотрим часть речи\n",
    "        if (gram_POS not in POS_list) & (gram_POS != None): # проверяем часть речи на наличие в списке и на тип None, который нам не нужен\n",
    "            POS_list.append(gram_POS) # добавляем часть речи, если проверка пройдена\n",
    "        else:\n",
    "            continue\n",
    "    return POS_list\n",
    "    \n",
    "def makePOSFreqDict(types, pos_list):\n",
    "    freqDict = nltk.FreqDist({pos:0 for pos in pos_list}) # создаём исходный словарь часть речи - количество слов\n",
    "    \n",
    "    for pos in pos_list: # последовательно идём по частям речи из списка\n",
    "        for t in types: # последовательно идём по всем типам\n",
    "            try:\n",
    "                gram_info = analyzer.parse(t)[0] # собираем информацию о слове\n",
    "                if pos == gram_info.tag.POS: # проверяем соответствие части речи слова и рассматриваемой части речи из списка\n",
    "                    freqDict[pos] += types[t] # увеличиваем количество, если части речи совпадают    \n",
    "                else:\n",
    "                    continue\n",
    "            except IndexError:\n",
    "                pass\n",
    "    return freqDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на части речи, встречающиеся в коллекции текстов публицистического стиля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VERB', 'NOUN', 'PREP', 'ADJF', 'ADVB', 'ADJS', 'PRTF', 'GRND', 'INFN', 'PRTS', 'NPRO', 'NUMR', 'PRCL', 'CONJ', 'PRED', 'COMP', 'INTJ']\n"
     ]
    }
   ],
   "source": [
    "publPOSList = makePOSList(publicistic_types)\n",
    "print(publPOSList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим частотный словарь часть речи - количество слов для коллекции текстов публицистического стиля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'ADJF': 645,\n",
       "         'ADJS': 39,\n",
       "         'ADVB': 104,\n",
       "         'COMP': 7,\n",
       "         'CONJ': 302,\n",
       "         'GRND': 14,\n",
       "         'INFN': 85,\n",
       "         'INTJ': 8,\n",
       "         'NOUN': 2312,\n",
       "         'NPRO': 117,\n",
       "         'NUMR': 28,\n",
       "         'PRCL': 83,\n",
       "         'PRED': 2,\n",
       "         'PREP': 706,\n",
       "         'PRTF': 63,\n",
       "         'PRTS': 62,\n",
       "         'VERB': 435})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publPOSFreqDict = makePOSFreqDict(publicistic_types, publPOSList)\n",
    "publPOSFreqDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно заметить выше, в собранной коллекции текстов публицистического стиля больше всего существительных - 2312 шт., затем следуют предлоги - 706 шт., тройку замыкают прилагательные - 684 шт. (645 в полной форме и 39 - в краткой)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим части речи, встречающиеся в коллекции текстов художественного стиля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NOUN', 'ADJF', 'ADVB', 'VERB', 'PREP', 'CONJ', 'GRND', 'PRED', 'INFN', 'ADJS', 'PRTS', 'PRCL', 'PRTF', 'NPRO', 'NUMR', 'COMP', 'INTJ']\n"
     ]
    }
   ],
   "source": [
    "fictionPOSList = makePOSList(fiction_types)\n",
    "print(fictionPOSList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим частотный словарь часть речи - количество слов для коллекции текстов художественного стиля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'ADJF': 620,\n",
       "         'ADJS': 55,\n",
       "         'ADVB': 329,\n",
       "         'COMP': 26,\n",
       "         'CONJ': 565,\n",
       "         'GRND': 60,\n",
       "         'INFN': 89,\n",
       "         'INTJ': 6,\n",
       "         'NOUN': 1435,\n",
       "         'NPRO': 431,\n",
       "         'NUMR': 31,\n",
       "         'PRCL': 198,\n",
       "         'PRED': 9,\n",
       "         'PREP': 559,\n",
       "         'PRTF': 71,\n",
       "         'PRTS': 13,\n",
       "         'VERB': 609})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fictionPOSFreqDict = makePOSFreqDict(fiction_types, fictionPOSList)\n",
    "fictionPOSFreqDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно заметить выше, в собранной коллекции текстов художественного стиля также больше всего существительных - 1435 шт., затем следуют прилагательные - 675 шт. (620 в полной форме и 55 - в краткой), тройку замыкают глаголы - 698 шт. (609 в личной форме и 89 - в начальной).<br><br>\n",
    "По сравнению с публицистическим стилем, рассматриваемая художественная коллекция содержит меньше существительных,  предлогов и причастий, но больше глаголов, прилагательных в краткой форме, союзов и наречий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3.</b> Посчитаем коэффициент корреляции Спирмена для полученных на предыдущем шаге частот частей речи.<br><br>\n",
    "Перед расчетом коэффициента корреляции Спирмена получим соответствующие по частям речи списки частот частей речи из созданных выше словарей. Это реализует созданная функция get_freqList."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Частоты для публицистического стиля: [645, 39, 104, 7, 302, 14, 85, 8, 2312, 117, 28, 83, 2, 706, 63, 62, 435]\n",
      "Частоты для художественного стиля: [620, 55, 329, 26, 565, 60, 89, 6, 1435, 431, 31, 198, 9, 559, 71, 13, 609]\n"
     ]
    }
   ],
   "source": [
    "def get_freqList(FreqDict): # возвращает упорядоченный список частот частей речи в соответствии со значениями из словаря\n",
    "    freqList = [] # создаем список количества слов\n",
    "    for i in sorted(FreqDict.keys()): # идём по отсортированному списку ключей из словаря часть речи - количество слов\n",
    "        freqList.append(FreqDict[i]) # добавляем в список количество слов, относящихся к части речи\n",
    "    return freqList\n",
    "\n",
    "publ_freqList = get_freqList(publPOSFreqDict) # список частот для коллекции публицистического стиля (по типам)\n",
    "fict_freqList = get_freqList(fictionPOSFreqDict) # список частот для коллекции художественного стиля (по типам)\n",
    "\n",
    "print(\"Частоты для публицистического стиля:\", publ_freqList)\n",
    "print(\"Частоты для художественного стиля:\", fict_freqList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для расчета коэффициента корреляции Спирмена для полученных на предыдущем шаге частот частей речи воспользуемся функцией spearmanr библиотеки scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение корреляциии Спирмена: 0.941176470588\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "spearman_cor = spearmanr(publ_freqList, fict_freqList)\n",
    "print(\"Значение корреляциии Спирмена:\", spearman_cor[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно заметить выше, значение корреляции Спирмена равно примерно 0.94. Следовательно, для данных двух коллекций текстов гипотеза о том, что в текстах публицистического и художественного стилей частоты частей речи имеют разные характеры распределений, отвергается. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
